{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCoOxzCj1xwn"
   },
   "outputs": [],
   "source": [
    "# instances for directories\n",
    "TRAIN_new = 'BTD/TRAIN_new/'\n",
    "VAL_new = 'BTD/VAL_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "tyNtCAEvOzAm",
    "outputId": "092e27d7-51e3-4804-cbd7-1d3f3d464a4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Performing Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "IMG_SIZE = (224,224)\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_new,\n",
    "    color_mode='rgb',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    seed=RANDOM_SEED)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VAL_new,\n",
    "    color_mode='rgb',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7asRwUakGr6v"
   },
   "outputs": [],
   "source": [
    "# load base model (Using VGG19 model here)\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vgg19_weight_path = 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model = VGG19(weights=vgg19_weight_path, include_top=False, input_shape=IMG_SIZE + (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "p7MJe1_CHK-v",
    "outputId": "0386c6c8-82ee-4d11-89ab-66ae619d3ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 25089     \n",
      "=================================================================\n",
      "Total params: 20,049,473\n",
      "Trainable params: 25,089\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Buidling model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "checkpath = 'weights.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.hdf5'\n",
    "cp = ModelCheckpoint(filepath=checkpath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    mode='auto')\n",
    "\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vomTc4g3in5I",
    "outputId": "786b00eb-abfe-44a1-bd1e-469f420bf7f0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - 312s 10s/step - loss: 3.1056 - accuracy: 0.7129 - val_loss: 8.2735 - val_accuracy: 0.7400\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 235s 7s/step - loss: 1.6611 - accuracy: 0.8613 - val_loss: 1.6355e-06 - val_accuracy: 0.8200\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 236s 7s/step - loss: 1.3237 - accuracy: 0.8760 - val_loss: 6.3245e-23 - val_accuracy: 0.7400\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 234s 7s/step - loss: 1.0943 - accuracy: 0.9043 - val_loss: 3.3171e-16 - val_accuracy: 0.8400\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 234s 7s/step - loss: 0.8633 - accuracy: 0.9023 - val_loss: 1.1814e-07 - val_accuracy: 0.9000\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 235s 7s/step - loss: 0.7388 - accuracy: 0.9238 - val_loss: 2.1962e-14 - val_accuracy: 0.8600\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 235s 7s/step - loss: 0.7374 - accuracy: 0.9287 - val_loss: 1.3047 - val_accuracy: 0.8200\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 235s 7s/step - loss: 0.6852 - accuracy: 0.9385 - val_loss: 0.0105 - val_accuracy: 0.8600\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 236s 7s/step - loss: 0.6070 - accuracy: 0.9385 - val_loss: 3.7875e-16 - val_accuracy: 0.8600\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 234s 7s/step - loss: 0.5217 - accuracy: 0.9375 - val_loss: 11.8843 - val_accuracy: 0.8400\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 235s 7s/step - loss: 0.6446 - accuracy: 0.9365 - val_loss: 0.9337 - val_accuracy: 0.8600\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 237s 7s/step - loss: 0.3894 - accuracy: 0.9619 - val_loss: 1.2111e-22 - val_accuracy: 0.8800\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 237s 7s/step - loss: 0.4548 - accuracy: 0.9551 - val_loss: 0.0000e+00 - val_accuracy: 0.8200\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 354s 11s/step - loss: 0.4965 - accuracy: 0.9541 - val_loss: 5.2773e-11 - val_accuracy: 0.8200\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 372s 12s/step - loss: 0.3999 - accuracy: 0.9619 - val_loss: 0.0148 - val_accuracy: 0.8600\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 372s 12s/step - loss: 0.6271 - accuracy: 0.9531 - val_loss: 4.3095e-11 - val_accuracy: 0.8600\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 370s 12s/step - loss: 0.5177 - accuracy: 0.9541 - val_loss: 6.3699 - val_accuracy: 0.8400\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 326s 10s/step - loss: 0.7743 - accuracy: 0.9365 - val_loss: 1.1332e-11 - val_accuracy: 0.7800\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 352s 11s/step - loss: 0.4072 - accuracy: 0.9697 - val_loss: 1.4080e-34 - val_accuracy: 0.8600\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 353s 11s/step - loss: 0.3183 - accuracy: 0.9707 - val_loss: 0.0000e+00 - val_accuracy: 0.7800\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 350s 11s/step - loss: 0.4737 - accuracy: 0.9600 - val_loss: 5.3805 - val_accuracy: 0.9000\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 342s 11s/step - loss: 0.6214 - accuracy: 0.9531 - val_loss: 4.4361e-10 - val_accuracy: 0.8200\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 245s 8s/step - loss: 0.4535 - accuracy: 0.9619 - val_loss: 8.1410e-25 - val_accuracy: 0.8200\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 244s 8s/step - loss: 0.4934 - accuracy: 0.9561 - val_loss: 46.2473 - val_accuracy: 0.8200\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 254s 8s/step - loss: 0.3872 - accuracy: 0.9658 - val_loss: 3.0727e-23 - val_accuracy: 0.8400\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 252s 8s/step - loss: 0.4255 - accuracy: 0.9668 - val_loss: 1.6265 - val_accuracy: 0.8800\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 240s 7s/step - loss: 0.6317 - accuracy: 0.9648 - val_loss: 2.6026e-27 - val_accuracy: 0.8400\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 273s 9s/step - loss: 0.5943 - accuracy: 0.9639 - val_loss: 9.1692e-05 - val_accuracy: 0.8800\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 261s 8s/step - loss: 0.4319 - accuracy: 0.9707 - val_loss: 2.7516e-11 - val_accuracy: 0.8600\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 269s 8s/step - loss: 0.3414 - accuracy: 0.9727 - val_loss: 0.0011 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=32,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=24,\n",
    "    callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RthV--z3hUhD"
   },
   "outputs": [],
   "source": [
    "# Saving the Model\n",
    "model.save('BTD_VGG19_version06')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BTD_VGG19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
