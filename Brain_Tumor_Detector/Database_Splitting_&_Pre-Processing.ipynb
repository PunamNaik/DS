{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0aYoSntRob6X",
    "outputId": "34ca9ee0-9bc3-4813-ab21-b69110b47463"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5DHHqU_or8l"
   },
   "outputs": [],
   "source": [
    "# function for splitting the dataset into train/val/test folder\n",
    "base_dir = 'BT/'\n",
    "\n",
    "for CLASS in os.listdir(base_dir):\n",
    "    if not CLASS.startswith('.'):\n",
    "        IMG_NUM = len(os.listdir(base_dir + CLASS))\n",
    "        for (n, FILE_NAME) in enumerate(os.listdir(base_dir + CLASS)):\n",
    "            img = base_dir + CLASS + '/' + FILE_NAME\n",
    "            if n < 5:\n",
    "                #shutil.copy(src, dst)\n",
    "                shutil.copy(img, 'BTD/TEST/' + CLASS.upper() + '/' + FILE_NAME)\n",
    "            elif n < 0.8*IMG_NUM:\n",
    "                shutil.copy(img, 'BTD/TRAIN/'+ CLASS.upper() + '/' + FILE_NAME)\n",
    "            else:\n",
    "                shutil.copy(img, 'BTD/VAL/'+ CLASS.upper() + '/' + FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBOyVBuG06m1"
   },
   "outputs": [],
   "source": [
    "# Functio for Image Pre-processing->finds the largest contour and crops the image at extreme points\n",
    "def img_pre_process(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    #cv2.imshow('original', image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    #cv2.imshow('gray', gray)\n",
    "    \n",
    "\n",
    "    ## threshold the image, then perform a series of erosions + dilations to remove any small regions of noise\n",
    "    thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    #cv2.imshow('binary', thresh)\n",
    "\n",
    "    ## find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    ## determine the most extreme points along the contour\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "    ## draw the outline of the object;\n",
    "    #cv2.drawContours(image.copy(), [c], -1, (0, 255, 255), 2)\n",
    "    #cv2.imshow(\"extreme_points\", image)\n",
    "\n",
    "    ## img crop at extreme points\n",
    "    x = extLeft[0]\n",
    "    w = extRight[0]\n",
    "    y = extTop[1]\n",
    "    h = extBot[1]\n",
    "    img_cropped = image[y:h, x:w]\n",
    "     \n",
    "    return img_cropped\n",
    "    #cv2.imshow('image_cropped', img_cropped)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCoOxzCj1xwn"
   },
   "outputs": [],
   "source": [
    "# Old directories(from where data to be fetched for pre-processing)\n",
    "TRAIN_DIR = 'BT/TRAIN/'\n",
    "TEST_DIR = 'BT/TEST/'\n",
    "VAL_DIR = 'BT/VAL/'\n",
    "\n",
    "# New directories(where data will be placed after preprocessing)\n",
    "TRAIN_new = 'BTD/TRAIN_new/'\n",
    "TEST_new = 'BTD/TEST_new/'\n",
    "VAL_new = 'BTD/VAL_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhc-l2TlsdzK"
   },
   "outputs": [],
   "source": [
    "# Performing pre=processing on TRAIN,TEST,VAL set\n",
    "def preprocess_db(db_dir, new_dir):\n",
    "    for CLASS in os.listdir(db_dir):\n",
    "        for n, file_name in enumerate(os.listdir(db_dir + CLASS)):\n",
    "            img_path = db_dir + CLASS + '/' + file_name\n",
    "            cropped_img = img_pre_process(img_path)\n",
    "            new_path = new_dir + CLASS + '/' + file_name\n",
    "            plt.imsave(new_path, cropped_img)\n",
    "\n",
    "preprocess_db(db_dir= TEST_DIR, new_dir=TEST_new)\n",
    "preprocess_db(db_dir= TRAIN_DIR, new_dir=TRAIN_new)\n",
    "preprocess_db(db_dir= VAL_DIR, new_dir=VAL_new)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BTD_VGG19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
